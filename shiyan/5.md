### 实验五

#### **P.475-476 Prob. 2-3**

##### 题目：

1、写程序实现 K-均值算法（算法 1）和模糊 K-均值聚类算法（算法 2）并用表中的三维数据进行测试。其中距离采用 Euclid 距离 d(x,y)=||x-y||。

(a)c=2，m1 (0) = (1,1,1)T，m2(0) = (-1,1,-1)T。

(b)c=2，m1 (0) = (0,0,0)T，m2(0) = (1,1,-1)T。将得到的结果与 (a) 中的结果进行比较，并解释差别，包括迭代次数的差别。

(c)c=3，m1 (0) = (0,0,0)T，m2(0) = (1,1,1)T ，m3(0) = (-1,0,2)T 。

(d)c=3，m1 (0) = (-0.1,0,0.1)T，m2(0) = (0,-0.1,0.1)T ，m3(0) = (-0.1,-0.1,0.1)T 。将得到的结果与 (c) 中的结果进行比较，并解释差别，包括迭代次数的差别。

2、重做 1，其中距离改为 〖d(x,y)〗^2=1-exp⁡(-β ∗|(|x-y|)|^2 )。其中β 分别取 0.001，0.01，0.1，1，10，100。

------

实验结果：

1、K均值聚类和模糊K均值聚类是两种常用的聚类算法。K均值聚类是一种硬聚类方法，每个数据点只能属于一个簇，通过迭代分配数据点到最近的质心并更新质心位置，直到收敛。而模糊K均值聚类是一种软聚类方法，允许每个数据点以一定的隶属度属于多个簇，通过迭代更新质心和隶属度矩阵，直到收敛。K均值适用于数据分布明确的情况，计算速度快，但对初始质心敏感；模糊K均值更灵活，能处理模糊边界，但计算复杂度较高。两者都是基于质心的迭代优化方法，需要预先指定簇的数量 k,而通过这个实验，可以更好的了解这两种算法的区别与联系，从而明白在何种情况选择合适的算法。

K均值聚类是一种硬聚类方法，它将数据集划分为 k 个簇，每个数据点只能属于一个簇。其主要步骤如下：

（1）初始化质心：随机选择 k 个初始质心。

（2）分配簇：对于每个数据点，计算它与每个质心的距离，并将其分配给距离最近的质心所属的簇。

（3）更新质心：计算每个簇的均值，并将质心更新为该均值。

（4）重复步骤2和3：直到质心的位置不再发生显著变化，或者达到最大迭代次数。

作为对比 ，模糊K均值聚类是一种软聚类方法，它允许每个数据点以一定的隶属度属于多个簇，主要步骤也类似，如下：

（1）初始化隶属度矩阵：随机初始化每个数据点对每个簇的隶属度。	

（2）计算质心：根据隶属度矩阵，计算每个簇的质心。

（3）更新隶属度矩阵：根据每个数据点到各质心的距离，更新隶属度。

（4）重复步骤2和3：直到隶属度矩阵不再发生显著变化，或者达到最大迭代次数。

所以根据这两个主要的步骤，可以写出代码，具体实现在5.1.cpp中，运行的结果如下：

![image-20240616152430528](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240616152430528.png)

对于结果来说，可以从以下方面来分析：

（1）初始质心影响：

- 不同的初始质心会导致不同的聚类结果和迭代次数。较好的初始质心能够更快收敛，减少迭代次数。
- 相似初始质心配置（如 centroids_1 和 centroids_2）的结果应更接近，而差异较大的初始质心配置（如 centroids_3 和 centroids_4）可能会有显著不同的聚类结果。

（2）K-均值 vs. 模糊K-均值：

- K-均值算法通常会收敛得更快，但对初始质心敏感，可能陷入局部最优解。
- 模糊K-均值算法通过模糊隶属度提供更平滑的更新，可能需要更多迭代，但结果对初始质心不太敏感。

2、对于第二问，是对点之间的距离的计算公式进行了更改，其他算法还是类似，具体实现的代码在5.2.cpp中，运行的结果如下：

![image-20240616154839618](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240616154839618.png)

![image-20240616155523622](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240616155523622.png)

![image-20240616155539651](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240616155539651.png)

从结果上来看，对于这两种算法，这里带来的影响差不多，总结如下：

（1）β 值的变化对结果的影响：

- 当 β 值较小时，距离的修改效果不显著，聚类结果接近于欧式距离的结果。
- 随着 β 值增大，距离的修改效果增强，聚类结果会明显偏离欧式距离的结果。
- β 值非常大时，距离几乎变为常数，导致聚类结果异常。

（2）与欧式距离结果对比：

- 小 β 值时，结果接近欧式距离。
- 大 β 值时，结果明显不同。

这个题目相比之前的还是简单一些，主要是聚类算法的实现，在本次实验中，对 K-均值和模糊 K-均值两种聚类算法进行了详细对比，并引入了一种基于指数函数的修改距离度量，考察了不同 β 值对聚类结果的影响，在实际应用中，合理选择 β 值，可以在一定程度上改善聚类效果，但需要注意的是，过大的 β 值可能导致聚类结果异常。因此，在聚类分析中，应根据具体数据特点和聚类目标，仔细选择合适的距离度量和参数，以获得最佳的聚类效果。