### 实验四

#### Prob.7

##### 题目：

1、研究“验证技术”未必会改善分类器的性能的情况。实验中分类器为“K-近邻分类器”，其中 K 是通过“验证技术”来设置。考虑一个三维的两类问题，其先验分布在范围 0 ≤ xi ≤ 1 (i=1,2,3) 内是均匀分布。

(a)首先形成一个 30 个点的测试集 Dtest — 15 个点属于 ω1 ，15 个点属于 ω2 — 并根据“均匀分布”的方式任意选出。

(b)接下来产生 120 个点 —— 每类 60 个模式。置 γ =0.15，将该集合划分成一个训练集 Dtrain （100 个点）和一个验证集 Dval （20 个点）。

(c)产生一个“K-近邻分类器”，其中 K 一直增加到验证误差的第一个极小值被找到。（限定 K 为奇数值，以避免出现不分胜负的情况）。现利用测试集来确定该分类器的误差。

(d)重复 (c)，但通过验证误差的第一个极大值来确定 K。

(e)重复 (c) 和 (d) 5 次，注意所有 10 种情况下的测试误差.

(f)讨论结论——尤其是，它们是如何的依赖于（或不依赖于）其数据是“均匀分布”的事实的。

------

##### 实验结果：	 

​		K近邻(K-Nearest Neighbor, KNN)是一种最经典和最简单的有监督学习方法之一。K-近邻算法是最简单的分类器，没有显式的学习过程或训练过程，是懒惰学习（Lazy Learning）。当对数据的分布只有很少或者没有任何先验知识时，K 近邻算法是一个不错的选择。这题就是要学习使用这个算法，并讨论一下验证技术。

​		所以，整体实验的思路还是挺明确的，如下：

1、**数据生成**：首先是生成三维数据点，均匀分布在[0,1]范围内。并打上0和1的label

2、**数据划分**：生成数据集，然后将生成的数据集分为训练集（100点）和验证集（20点）。

3、**KNN分类器**：计算点之间的欧几里得距离，并进行分类。

4、**K值选择**：

- `findFirstLocalMinimumK` 函数通过验证误差的第一个局部最小值选择K值。
- `findFirstLocalMaximumK` 函数通过验证误差的第一个局部最大值选择K值。

5、**多次实验**：重复实验5次，每次都记录测试误差，并输出所有实验的结果。

​	思路明确，代码实现都在4.1.cpp，运行代码，就可以输出结果，如下：           

![image-20240612203833004](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240612203833004.png)

针对(f)，思考如下：

​		首先是K值选择方法的影响:实验结果显示，选择验证误差的第一个局部最小值作为K值时，测试误差较低且较稳定。而作为对比的选择验证误差的第一个局部最大值作为K值时，测试误差波动较大；这是因为局部最小值通常对应较为适合的数据点数量，能够较好地平衡模型的偏差与方差，而局部最大值可能对应过大的K值，导致模型的泛化性能较差。所以，选择验证误差的第一个局部最小值作为K值在均匀分布的数据集上具有较好的效果。

​		然后是均匀分布的影响：在均匀分布的数据集中，各类别的数据点均匀分布在整个空间中。这种均匀性减少了样本间的极端差异，使得KNN分类器在不同K值下的表现相对稳定，这在输出结果中也能体现；同时，数据均匀分布使得验证集能够较好地代表总体数据，从而在选择K值时更具代表性。因此，通过验证误差选择K值的方法在均匀分布的数据集上具有较好的效果。

​		这个实现相比前面来说还是简单一些的，也不需要画图，主要就是实现一个K-近邻分类器，这个实验设计很好地展示了验证技术在机器学习中的关键作用，通过划分验证集并监测验证误差来选择最优的超参数，如K值，可以有效提高模型的泛化能力。数据分布的选择也对模型性能产生影响，实验中采用均匀分布使得模型更具一般性。超参数调优和实验设计的严谨性也在实验中得到了体现，通过多次实验和对比分析得出的结论更具可信度和泛化性，这些对于机器学习模型的优化和应用都有着重要意义。