### 实验一

#### Prob.1

对于第一题，主要考验的是高斯概率密度模型和最大似然估计。高斯模型，也被称为正态分布模型，是统计学中最为常见和重要的概率分布模型之一，还是比较熟悉的；最大似然估计（Maximum Likelihood Estimation, MLE）是一种用于估计统计模型参数的方法。

##### (a)编写程序，对表格中的类 ω1 中的 3 个特征 xi，分别求解最大似然估计 μ 和 σ2 ；

对于一维数据，MLE用于估计均值μ和方差σ²，最大化对数似然函数，就能得到参数的估计，从而编写代码进行运算。

具体实现在1.1.cpp中，主要实现了一个MLE类用来存储和计算均值和方差，运行结果如下：

![image-20240605151002120](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240605151002120.png)

分别对应三个特征。这第一问还是比较简单的，直接计算输出结果就行。

##### (b)处理二维数据，处理 ω1 中的任意两个特征的组合；

 对于二维数据，最大似然估计（MLE）可以用于估计均值向量和协方差矩阵，通过最大化对数似然函数，能得到参数的估计值，从而编写代码进行运算。

具体实现在1.2.cpp中，主要是实现了一个MLE类来存储和计算均值向量和协方差矩阵，运行结果如下：

![image-20240605153101965](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240605153101965.png)

计算了x1与x2特征组合的结果，比上一问难了一些，还行。

##### (c)处理三维数据，处理 ω1 中的三个特征的组合；

对于三维数据，最大似然估计（MLE）可以用于估计三维均值向量和3x3协方差矩阵，通过最大化对数似然函数，就能得到参数的估计值，从而编写代码进行运算。

具体实现在1.3.cpp中，主要是实现了一个MLE类来计算和存储三维均值向量和3x3协方差矩阵。运行结果如下：

![image-20240605153523982](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240605153523982.png)

前三问还是比较类似的，只是维度不同，处理方法都是类似的。

##### (d)在这三维高斯模型可分离的条件下，编写程序估计类别 ω2 中的均值和协方差矩阵中的 3 个参数；

在分离条件下，三维高斯模型的协方差矩阵可以被假设为对角矩阵，即各个维度之间的相关性为零。这简化了估计过程，因为协方差矩阵只有对角元素非零，其他元素均为零。

对数似然函数就被简化了，最大化对数似然函数，可以分别估计均值和三个方差的参数，从而编写代码进行运算。

具体实现在1.4.cpp中，主要是实现了一个SeparableGaussianMLE类用来存储和计算均值和协方差矩阵中的 3 个参数，运行结果如下：

![image-20240605154555112](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240605154555112.png)

##### (e)比较前 4 种方式计算出来的均值的异同，并加以解释；

通过之前知识的学习和代码的编写，可以发现以下的异同：

1、均值计算一致性：

- 无论数据是一维、二维还是三维，均值的计算方法都相同：所有数据的和除以数据的数量。
- 对于三维数据的分离高斯模型，虽然协方差矩阵的计算简化了，但均值的计算方法没有改变。

2、数据维度影响：

- 数据的维度只影响均值向量的维度（一维为标量，二维为二维向量，三维为三维向量），但均值计算的核心公式不变。

这表明均值计算的通用性和一致性。

##### (f)比较前 4 种方式计算出来的方差的异同，并加以解释。

通过对比可以发现，方差的计算方法和结果由于维度和假设的不同而有所差异：

1、一维方差：结果是一个单一的方差值，反映所有数据的离散程度。

2、多维协方差矩阵：

- 二维和三维协方差矩阵：不仅包括每个维度的方差，还包括维度之间的协方差，反映维度之间的相关性。
- 分离高斯模型：假设维度之间独立，协方差矩阵为对角矩阵，忽略了维度之间的协方差，简化了计算。

------

#### Prob. 9

Fisher 线性判别方法是一种常用的监督学习方法，用于在高维数据中找到最佳的线性投影方向，以实现数据降维或分类等任务。

##### (a)编写用 Fisher 线性判别方法，对三维数据求最优方向 w 的通用程序；

在1.5.cpp中，fisherLinearDiscriminant函数是用来计算三维数据的最优方向 w的函数；

##### (b)对表格中的类别 ω2 和 ω3，计算最优方向 w；

输入数据，再调用a中提到的函数，就可以得出结果了，运行的结果如下：

![image-20240605162422178](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240605162422178.png)

##### (c)画出表示最优方向 w 的直线，并且标记出投影后的点在直线上的位置；

在c++中画图还是比较麻烦的，需要使用第三方库OpenCV，配好环境后，将数据点和直线都绘制出来就可以 了。

![image-20240605163206344](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240605163206344.png)

线上的红点与原本红点对应，线上的蓝点与原本蓝点对应。

##### (d)在这个子空间中，对每种分布用一维高斯函数拟合，并且求分类决策面；

##### (e)(b) 中得到的分类器的训练误差是什么？

计算的步骤如下：

1、计算一维高斯分布的均值和方差：

对于每个类别的数据，计算投影后的均值和方差。

2、计算一维高斯分布的概率密度函数：

使用计算得到的均值和方差，计算一维高斯分布的概率密度函数。

3、求分类决策面：

利用高斯分布的概率密度函数，求解两个类别的分布交点作为分类决策面。

4、计算误差率：

通过决策面，将数据点进行分类，并计算分类错误的比例。

##### (f)为了比较，使用非最优方向 w=(1.4, 2.7, -1.2)T 重复 (d)(e) 两个步骤。在这个非最优子空间中，训练误差是什么？

这个实现就和上面差不多，还是那几个步骤：

1、投影数据：将数据投影到非最优方向 w 上。

2、拟合高斯分布：对投影后的数据进行高斯分布拟合，计算均值和方差。

3、计算决策边界：根据高斯分布的参数，计算分类决策边界。

4、计算分类错误率：根据决策边界，计算分类错误率。

def的实现代码在1.5-2.cpp中，运行的结果如下：

![image-20240605165839407](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240605165839407.png)

可以看到非最优方向的误差率还是会更高一些的。

实验一整体来说还是较为简单的，问题一更容易一些，而对于问题二，还需要在c++上配置opencv环境，并且计算方法也复杂一些，实现起来更为麻烦一些。不过通过实现也了解了基础的最大似然估计和线性判别分析，还是有些收获的。