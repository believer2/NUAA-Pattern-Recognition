### 实验六

##### 题目：

(a)用 PCA 方法对实验图像设计分类器并完成训练和分类过程，统计正确分类率，其中求解特征值和特征向量的方法分为一般方法和使用技巧 [1] 的方法，比较二者的运行时间和正确分类率；

(b)用 MDA 方法对实验图像设计分类器并完成训练和分类过程，统计正确分类率。

实验图像库为 ORL 人脸图像库，共 40 人，随机选取 25 人，每人 10 幅图像，选取其中 5 幅图像，对比做两种不同的数据增广（增广策略不限，包括图像翻转、裁剪、颜色调和等），并与原始数据合并为训练样本，剩余 5 幅作为测试分类样本，统计正确分类率。分类准则为最近邻规则。(报告需展示原始以及增广后的图像)

(c) 用距离保持的降维法 (DPDR) [2] 进行同样的实验并与 PCA 比较。

(d) 考察 PCA 与 DPDR 的外推能力，即设 TrSet 和 TeSET 分别为训练和测试数据集，

​     现在Step 1：用 TrSet 获得投影阵 M，用其重建 TeSET，计算重建误差 ETE，

  Step 2：用 TrSet+TeSET 获得投影阵 M+，用其重建 TeSET+，计算重建误差 ETE+，

  Step 3：比较ETE 和 ETE+，你能获得何种发现？

------

##### 实验结果：

（a) PCA（Principal Component Analysis）是常用的数据分析方法。PCA是通过线性变换，将原始数据变换为一组各维度线性无关的数据表示方法，可用于提取数据的主要特征分量，常用于高维数据的降维。这个题目的话，主要对人脸的训练数据进行主成分分析（PCA），从而提取数据的主要特征并降低数据维度。这里保留了的主成分数量为50个。

实验步骤如下：

1. 数据加载：从文件夹中读取图像，并分为训练集和测试集。
2. 数据预处理：将图像展平为向量，并进行标准化处理。
3. PCA计算
   - 一般方法：使用标准的协方差矩阵计算方法。
   - 技巧方法：使用技巧加速PCA计算的方法。
4. 训练分类器：使用最近邻分类器。
5. 评估分类器：计算并比较分类器的正确分类率和运行时间。

代码具体实现在6.1.cpp中，运行的结果如下：

![image-20240623145202960](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240623145202960.png)

​		从结果可以看出，虽然SVD方法比常规PCA方法在时间上慢了一些，但在捕捉数据的主成分方面是等效的，因此分类准确率是相同的。PCA的目标是找到数据的主成分，SVD方法和协方差矩阵分解方法在数学上等价，因此在捕捉数据主成分的能力上是相同的。而时间上，SVD的计算复杂度通常高于协方差矩阵的特征值分解。对于较小的数据集，协方差矩阵分解方法可能更快。所以在不同情况，可以根据具体应用选择适当的方法。如果数据维度非常高或存在数值稳定性问题，可以考虑使用SVD方法。

​		这题实现起来太困难了，读取数据就很费事，然后实现pca计算也很麻烦，存在的bug也很多，opencv需要的数据格式很费事，一直在调试，不过最终的结果还是可以，得到了还不错的数据结果，也了解了这不同方法的区别。

（b)最大差异分析 (Maximum Discriminant Analysis, MDA) 是一种用于降维和分类的统计方法，其目标是通过最大化类间差异和最小化类内差异来实现对数据的有效区分。MDA 通常用于模式识别和机器学习中的分类问题。

​		这个与a最大的区别就是使用的是performMDA函数对训练数据进行多判别分析（MDA），用于特征提取和降维。该函数计算类内散布矩阵和类间散布矩阵，然后求解特征值和特征向量以找到最具区分性的特征。但是在实验中，计算得到的类内散布矩阵（S_W）和类间散布矩阵（S_B）特别大，导致计算过程特别慢。。。计算 S_W 和 S_B 的过程需要较长时间，所以尝试降低数据维度：考虑使用降维技术（如上一问中的主成分分析 PCA）来减少特征数量，从而降低计算复杂度。

​		使用了降维操作后，运行起来快了很多，然后出来的正确率只有4%，调了好多参数，还是4%，很难受，最后调了分类准则为最近邻规则，运行出来的正确率达到了30+%，然后调整k的值的话，正确率还是在这附近。最终调也调也调不出来更好的结果。。。

​		关于数据增广，做了图像翻转这种数据的增加，效果如下：

![image-20240623151719921](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240623151719921.png)

水平翻转了一下，然后再进行训练识别的话，正确率只有百分之十几了。。。心累，也调不出来更好的了。

具体实现的代码在6.2.cpp中，运行结果如下，下面是数据增广后的结果：

![image-20240623151901179](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240623151901179.png)

![image-20240623151917781](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240623151917781.png)

这个题目比上一题更难。。。实现起来又更费事了，并且最终的结果也不是特别好，调试过程真的麻烦，带来的结果也不是特别好，所以在具体问题中，选择适当的特征降维方法和增广策略，可能会带来更好的结果。

（c）DPDR (Distance Preserving Dimensionality Reduction) 是一种降维方法，它的目标是通过保持数据点之间的距离关系来实现降维，即在降维的过程中尽可能地保留数据点在原始高维空间中的距离关系。DPDR 的核心思想是在降维过程中保持数据点之间的相对位置关系，尽可能地保留原始数据的结构和信息，以便在降维后仍能有效地进行数据分析和处理。

实现思路也和之前类似，就是将方法换成DPDR，所以具体实现在6.3.cpp中，实现过程又比较麻烦，调bug真烦啊，然后出来的结果如下：

![image-20240624150403238](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240624150403238.png)

调了很多参数去试，但是最终的结果就是不是很好，不知道为啥，难啊。。。

​		总结如下：使用距离保持的降维法（DPDR）和第一问使用的主成分分析（PCA）来对人脸图像数据集进行降维，并使用K最近邻（KNN）算法进行分类。实验结果总结如下：实验中发现，使用PCA进行降维后，KNN分类器的准确率达到了95%，而使用DPDR进行降维后，准确率较低，仅为7%至13%。这个结果可能受到多个因素的影响，包括降维后特征的表征能力、KNN算法对特征空间的敏感程度等。只能说是猜测，具体也不知道为啥，在实际情况肯定选择效果更好的算法；为了尝试提高DPDR的性能，调整了超参数，包括目标维度、K值以及KNN算法的距离权重等。然而，即使调整了这些参数，最终的准确率仍然较低，说明DPDR在这个任务上可能不如PCA适用。

（d）这个题目思路还是挺明确的，直接按照题目中的要求实现就可以了，具体实现在6.4.cpp中，运行的结果如下图：

![image-20240624164521129](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240624164521129.png)

当开始实验时，首先遇到了重构误差异常高的问题。这是由于一些潜在的因素，可能是数据集的大小或者数据处理过程中的错误，不太懂，每个程序都要调好久，麻了，在经过一些调试和调整后，成功地将重构误差控制在了一个相对合理的范围内。

在实验过程中，PCA（主成分分析）在降维方面表现出色。通过调整目标维度和合并数据集等方法，能够获得较低的重构误差。这表明PCA在保留数据信息的同时，有效地减少了数据的维度，提高了模型的运行效率。与此相比，DPDR（判别度投影降维）在一些情况下重构误差较高。这可能是因为DPDR更加注重于数据的判别性，而在降维过程中可能丢失了部分数据的信息。因此，在选择降维方法时，需要综合考虑数据的特点以及任务的要求。

总结：通过这次实验，我不仅学到了如何使用OpenCV库进行图像处理和机器学习任务，还了解了不同的降维方法及其在人脸识别等领域的应用。在未来的工作中，我将更加注意数据的预处理和参数调优，以获得更好的降维效果和模型性能。