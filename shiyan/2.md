### 实验二

##### 题目：

用课本中第五章算法 3~12 （除算法 8 外）在 Iris 数据集上进行分类。

 (a) 对 class1 与 class3 采用算法 3~12（除算法 8 外），从每类中随机选取 40 个样本用于训练分类器，其余 10 个样本用于测试分类器，重复该过程多遍，估计分类精度的均值及方差；

(b) 对 class2 与 class3 采用相应的算法，从每类中随机选取 40 个样本用于训练分类器，其余 10 个样本用于测试分类器，重复该过程多遍（100 遍），估计分类精度的均值及方差；

------

##### 实验结果：

首先需要了解每个算法原理以及如何实现的流程：

3、批处理感知算法

批处理感知器是一种线性分类算法，它通过不断调整权重向量来将数据分类到不同的类中。流程如下：

（1）初始化权重向量为零。

（2）对于每个样本，将特征与权重做内积，如果分类错误，则调整权重。

（3）重复步骤2，直到所有样本分类正确或达到最大迭代次数。

4、固定增量单样本感知器

单样本感知器也是一种线性分类算法，与批处理感知器不同，它在每次处理一个样本时就调整权重。流程如下：

（1）初始化权重向量为零。

（2）依次处理每个样本，将特征与权重做内积，如果分类错误，则立即调整权重。

（3）重复步骤2，直到所有样本分类正确或达到最大迭代次数。

5、带裕量的变增量感知器

裕量感知器是感知器算法的一个变种，通过引入一个分类裕量来增强分类的稳定性。流程如下：

（1）初始化权重向量和分类裕量。

（2）依次处理每个样本，将特征与权重做内积，如果分类错误或分类裕量小于指定值，则调整权重。

（3）重复步骤2，直到所有样本分类正确或达到最大迭代次数。

6、批处理变增量感知器

批处理变增量感知器结合了批处理感知器和裕量感知器的特点，使用批处理方式处理样本并考虑分类裕量。流程如下：

（1）初始化权重向量和分类裕量。

（2）对于每个样本，将特征与权重做内积，如果分类错误或分类裕量小于指定值，则调整权重。

（3）重复步骤2，直到所有样本分类正确或达到最大迭代次数。

7、平衡Winnow算法

平衡Winnow算法是一种用于二分类的乘法更新算法，适用于高维稀疏数据。流程如下：

（1）初始化权重向量为1。

（2）依次处理每个样本，将特征与权重做内积，如果分类错误，则按样本特征值调整权重：特征值为正则乘以alpha，特征值为负则乘以beta。

（3）重复步骤2，直到所有样本分类正确或达到最大迭代次数。

9、单样本裕量松弛算法

单样本裕量松弛算法是一种基于感知器的分类算法，通过引入松弛变量来处理线性不可分的情况。流程如下：

（1）初始化权重向量和松弛变量。

（2）依次处理每个样本，将特征与权重做内积，考虑松弛变量进行分类，如果分类错误，则调整权重和松弛变量。

（3）重复步骤2，直到所有样本分类正确或达到最大迭代次数。

10、LMS算法

最小均方（LMS）算法是一种用于函数逼近和自适应滤波的线性回归算法，通过最小化预测误差的均方来调整权重。流程如下：

（1）化权重向量为零。

（2）依次处理每个样本，将特征与权重做内积，计算预测误差，按误差调整权重。

（3）重复步骤2，直到预测误差收敛或达到最大迭代次数。

11、Ho-Kashyap算法

Ho-Kashyap算法是一种用于线性可分数据的分类算法，通过调整分类平面使得样本点距离分类平面的距离最大化。流程如下：

（1）初始化权重向量和偏置向量。

（2）计算每个样本的误差，如果误差为负，则调整偏置向量。

（3）按误差调整权重向量，直到所有样本分类正确或达到最大迭代次数。

12、修改的Ho-Kashyap算法

修改的Ho-Kashyap算法是Ho-Kashyap算法的改进版，通过修改误差和偏置向量的调整方式来增强算法的收敛性。流程如下：

（1）初始化权重向量和偏置向量。

（2）计算每个样本的误差，按误差调整偏置向量和权重向量。

（3）如果偏置向量为负，则将其设为零。

（4）重复步骤2，直到所有样本分类正确或达到最大迭代次数。

基本的算法都了解过后，就需要确定整个实验的流程，要在 Iris 数据集上使用特定的算法进行分类，可以采用以下步骤：

（1）加载数据集：读取 CSV 文件并提取所需的 class1（或者class2）和 class3 样本。

（2）数据预处理：将类别标签转换为二分类任务的标签。

（3）划分数据集：随机选取每类中的 40 个样本用于训练，其余 10 个样本用于测试。

（4）定义分类算法：实现所需的各个算法（结合上面介绍的思路用代码实现）

（5）训练与测试：对每个算法进行多次训练和测试，计算分类精度的均值和方差。

具体的代码实现在2.1.cpp中，通过运行代码，结果如下：

![image-20240618170741933](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240618170741933.png)

将代码中的 preprocess_data函数中的label中的0改为1，就可以对对 class2 与 class3 采用相应的算法了，结果如下，与上面的差别不是很大

![image-20240618194008156](C:\Users\cky\AppData\Roaming\Typora\typora-user-images\image-20240618194008156.png)

可以看到大部分的算法都是很好的分类，但是，有一些算法（例如Balanced Winnow、Ho-Kashyap和Modified Ho-Kashyap）表现较差，我尝试调参数，或者是修改算法的形式，都没有很好的效果。。。我也不知道具体是因为什么，调了好久还是没有很好的效果。。。最终分析了一下，相比于其他算法，这几个算法可能具有更高的复杂度和参数调整要求，需要更多的调优和改进才能在特定数据集上发挥较好的效果。例如，通过学习，知道了Balanced Winnow 算法是一种在线学习算法，主要用于处理高维稀疏数据，由于每次误分类时权重都会成倍增长或缩减，需要对每个特征进行调整，计算复杂度较高；而且这个算法依赖于多个参数，如调整因子（promotion and demotion factors），需要精细调整才能获得最佳性能。

这个实验真的做的挺难的，每个算法都要学习并不且实现，然后有的算法还需要调参数等等，通过此次实验，不仅验证了多种经典线性分类算法在Iris数据集上的性能，还积累了宝贵的经验和见解，首先，不同的算法在不同的数据集上表现可能截然不同。选择合适的算法是关键，需要充分了解数据集的特性和算法的适用范围；其次，是写代码的过程中，一些算法的表现可能因为参数设置不当而受到影响，所以调参数也是重中之重。此次实验不仅帮助理解了各类线性分类算法的实际应用效果，还在今后的机器学习项目中选择和应用合适的算法提供了宝贵的参考。

